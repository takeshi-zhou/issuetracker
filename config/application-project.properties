server.port=8002

#mybatis配置
mybatis.type-aliases-package=cn.edu.fudan.projectmanager.domain
mybatis.mapperLocations=classpath:mapper/*.xml
#编码配置
spring.http.encoding.force=true
spring.http.encoding.charset=UTF-8
spring.http.encoding.enabled=true
#JSON返回前端时的格式化
spring.jackson.date-format=yyyy-MM-dd HH:mm:ss
spring.jackson.time-zone=GMT+8


#数据源配置
spring.datasource.name=mysql_druid
spring.datasource.type=com.alibaba.druid.pool.DruidDataSource
spring.datasource.url=jdbc:mysql://10.131.252.160:3306/issueTracker?characterEncoding=utf8&useSSL=false&allowMultiQueries=true&autoReconnect=true 
spring.datasource.username=root
spring.datasource.password=HxUR7gT1dLQwPDUwO0SR02gsJj4wxZHbadojloQt4xRPeSLL0FGgn4qwbwC2+/A3YRw3LgrduBjAbey/MJSqjQ==
public-key=MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBAKG3KtWNiPBAzJQNaG/wnMZpb8gATF2Rr+E84udC2Db35eZEBmD57Hu/3+AHCKY1vw73oDLuve0+u4SKba4M21cCAwEAAQ==
spring.datasource.driver-class-name=com.mysql.jdbc.Driver
spring.datasource.druid.filter.config.enabled=true
spring.datasource.druid.connection-properties=config.decrypt=true;config.decrypt.key=${public-key}
#redis配置
# Redis数据库索引(默认为0)
spring.redis.database=0
# Redis服务器
spring.redis.host=127.0.0.1
# Redis端口
spring.redis.port=6379
# Redis密码
spring.redis.password=85redis

#kafaka配置
#kafka服务器地址
spring.kafka.bootstrap-servers=127.0.0.1:9092
#kafaka消费者配置
# earliest:当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，从头开始消费
# latest:当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，消费新产生的该分区下的数据
# none:topic各分区都存在已提交的offset时，从offset后开始消费；只要有一个分区不存在已提交的offset，则抛出异常
spring.kafka.consumer.auto-offset-reset=latest
#每一个Consumer都会属于某个Group,通常一个Group下会有多个Consumer
spring.kafka.consumer.group-id=test
spring.kafka.consumer.enable-auto-commit=true
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
#Kafka生产者配置
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.acks=1

account.service.path=http://127.0.0.1:8001
project.service.path=http://127.0.0.1:8002
scan.service.path=http://127.0.0.1:8003
issue.service.path=http://127.0.0.1:8005
event.service.path=http://127.0.0.1:8007
repository.service.path=http://127.0.0.1:8102/repository
#repo.url.pattern=http://200.31.147.77/[\\w-_\\.]+/[\\w-_\\.]+[/\\w-_\\.]{0,}
repo.url.pattern=https://github.com(/[\\w-]+/[\\w-]+)
github.api.path=https://api.github.com/repos
workHome=/home/fdse/user/issueTracker/
clone.result.pre.home=${workHome}saga-cpu/perFile/