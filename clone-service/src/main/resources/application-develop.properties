server.port=8886

#redis配置
# Redis数据库索引(默认为0)
spring.redis.database=0
# Redis服务器
spring.redis.host=10.141.221.85
# Redis端口
spring.redis.port=6379
# Redis密码
spring.redis.password=85redis



#kafaka配置
#kafka服务器地址
spring.kafka.bootstrap-servers=10.141.221.85:9092
#kafaka消费者配置
# earliest:当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，从头开始消费
# latest:当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，消费新产生的该分区下的数据
# none:topic各分区都存在已提交的offset时，从offset后开始消费；只要有一个分区不存在已提交的offset，则抛出异常
spring.kafka.consumer.auto-offset-reset=latest
#每一个Consumer都会属于某个Group,通常一个Group下会有多个Consumer
spring.kafka.consumer.group-id=test
spring.kafka.consumer.enable-auto-commit=true
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
#Kafka生产者配置
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.acks=1

workHome=E:/clone_service_test
log.home=E:/clone_service_test/Log/
resultFileHome=E:/clone_service_test/res/
shareDir=Y:/
repoHome=Y:/github/
commit.service.path=http://10.141.221.85:8102/commit
inner.service.path=http://10.141.221.85:8000
inner.header.key=apikey
inner.header.value=vzPh6QXeja2sjtxg0O0X5e2v9JqLELVO
